


[![button](prevsectionv3.png)](tutorial_section4.html) | [![button](nextsectionv3.png)](tutorial_section6.html)

## Section 4: Getting Heatmaps for WISs
In this section we explain how to efficiently get output maps (e.g. output activations of a CNN) for huge whole-slide-images in
PyDmed.
In doing so, we introduce two tools in different subsections:
1. Sliding window dataloader, implemented by the class `pydmed.extensions.wsi.SlidingWindowDLTODO:check`.
2. Collecting and processing a stream of smallchunks.   

### Sliding-window dataloader
Sliding-window dataloader considers a square of a specific size (a square of size `kernel_size`), and slides
 it over a whole-slide-image with a specific stride as set by the variable `stride`.
 
The below figure illustrates how the sliding-window dataloader returns patches.
![Alt Text](slidingwindowdl.gif)


In [section 2](tutorial_section2.html) we discussed how to create a dataloader.
Making a sliding-window dataloader is almost the same.
The only difference is that sliding-window dataloader (i.e., `SlidingWindowDLTODO`)
needs few additional arguements. The below code illustrates how to create a sliding-window dataloader:
```python
TODOTODOTODO
``` 
The `SlidingWindowDLTODO` has 4 additional arguments compared to the normal dataloader we discussed in
[section 2](tutorial_section2.html):
1. `intorfunc_opslevelTODO`: This arguments specifies the pyramidal image's level from which the patches
are going to be extracted. For example when this argument is set to 1, patches will be extracted from level 1.
In histopathology datasets it is quite common to have slides which are scanned at different magnification levels.
For instnace in a dataset some of the slides might be scanned at $20x$ magnification level, while some others at $40x$ magnification level.
In this case, one may need to consider the level based on magnification level (e.g. level 0 for $40x$ slides and level 1 for $20x$ slides).
For doing so, you can implement a function that decides a specific level for each WSI. Afterwards, you need to
pass the function as the argument `intorfunc_opslevelTODO`. The below code demonstrates the procedure:
```python
TODOTODOTODO
```
2. `kernel_sizeTODO`: an integer, the width of the sliding-window. This argument is analogous to 
the `kernel_size` argument of, e.g., [pytorch's Conv2d module](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html).
3. `strideTODO`: an integer, the amount of shift of the sliding-window in each step.
This argument is analogous to 
the `stride` argument of, e.g., [pytorch's Conv2d module](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html).
4. `mininterval_loadnewbighunck`: the minimum time (in seconds) between loading two BigChunks.
The value is typically between 10 and 30 based on the mahcine being used.
In case you noticed the dataloader is demanding too much from the machine, you can increase this argument. 


### Processing a stream of small-chunnks
So far we saw how `SlidingWindowDLTODO` makes a stream of `SmallChunksTODO`.
But how to process these smallchunks and produce, e.g., a heatmap?
For huge whole-slide-images, heatmaps also become very huge, and it is not often possible to store them in RAM.
Indeed, once a samllchunks if processed the processed information must be written to disk 
(instead of saving the processing result in RAM).
For doing so, PyDmed provides a simple yet effective abstraction as illustrated by the following figure:
![overview of streamcollector functionality](streamcollector.png)
The process of getting, e.g., heatmaps for WSIs has three components:
1. Dataloader: A dataloader (in this case `SlidingWindowDLTODO`) makes a stream of patches.
2. StreamCollector: This component recieves the stream of smallchunks generated by the dataloader.
After processing one smallchunk, the StreamCollector hands over the "processed piece" (for instance the value of
heatmap for that specific smallchunk) to the next step.
3. StreamWriter: this component receives a stream of processed pieces and writes them on disk.

Please note that the three above components are done by different processes.
Specificly, the first and the third components make disk read/writes in a parallel way.
Therefore, the above scheme is very efficient. 
PyDmed provides a straightforward way to make a customized StreamCollector. 
For doing so, you can make a subclass from `StreamCollectorTODO`.
You are required to implement two methods:
1. the function `process_piceeofstreamTODO`: This function specifies how the outputs from the dataloader
are processed. More precisely, given some return values from the dataloader, in `process_piceeofstreamTODO` 
you need to process the smallchunks and return a set of `ProcessedPieceTODO`s. 
2. the fucntion `get_flag_finishcollectingTODO`: In this fucntion you should decide whether the whole processing
has been finished. If it is finished, you have to return True and you have to return False otherwise.
For the sliding window dataloader, you can leave the function `get_flag_finishcollectingTODO`
as implemented in the below code.

The below box demonstrates how to build a `StreamCollectorTODO` get a heatmap for WSIs:
```python
TODOTODOTODO
```
Afterwards, you can simply make an instance from `HeatmapStreamCollectorTODO` and call its `start_collecting()TODO`
function:
```python
TODOTODO
```

For each `Patient`, a separate csv file will be created.
Getting heatmap for WISs takes several minutes. 
After several minutes, all information to get heatmaps will be saved on those csv file.
Each line of those csv files includes the following information:
TODOTODO.
     

      



[![button](prevsectionv3.png)](tutorial_section4.html) | [![button](nextsectionv3.png)](tutorial_section6.html)

